
[Google Scholar](https://scholar.google.com/citations?user=YmWi1lgAAAAJ&hl=en) / [Github](https://github.com/hanqi-qi) / [Twitter](https://twitter.com/yan_hanqi) / [LinkedIn](https://www.linkedin.com/in/hanqi-yan-9211a91b1/?originalSubdomain=uk)

Hanqi Yan 颜寒祺
Email: [hanqi.yan@kcl.ac.uk](hanqi.yan@kcl.ac.uk)

I am a Ph.D. student(2020fall) at the University of Warwick & Kings' College London (KCL) with professor [Yulan He](https://sites.google.com/view/yulanhe/home). I finished my M.S. at [Peking University](https://english.pku.edu.cn/) (2017-2020) in Academy for Advanced Interdisciplinary Studies and my B.E. at [Beihang University](https://ev.buaa.edu.cn/) (2013-2017) in Information Engineering Department. 

> During Ph.D., I started my Causality Journey in visiting professor [Kun Zhang](https://www.andrew.cmu.edu/user/kunz1/) affiliated with **Causal Learning and Reasoning (CLeaR) Group** at CMU and Center for **Integrative AI (CIAI)** at MBZUAI (2022.10-2023.02).

> Before Ph.D., I started my NLP journey in visiting professor [Wenjie Li](https://www4.comp.polyu.edu.hk/~cswjli/) affiliated **Natural Language Processing Group @PolyU Hong Kong** (2019.07-2019.10).

```I study **interpretable** and **robust** representations for NLP models:
* In the LLM era, I focus on constrained planning (search) in the model decoding phrase, to achieve _safe_, _reliable_ and _fair_ outputs.
* Considering the stochastic nature of the current deep neural networks, we are able to align the models' behaviors with human knowledge.
* The Deep Learning model is built on certain inductive biases and sample selection biases. We propose empirical and principled methods to alleviate representation bias and learn robust representations across various testing environments.


I am expected to graduate in October 2024 and will be on academic job market in the UK and US.
```

## Education
* 2020 - 2023. Ph.D. at University of Warwick & Kings' College London(KCL). Interpretable and Robust NLP
* 2018 - 2020. M.S. at Peking University. Sentiment Analysis & Spatial Data Mining
* 2013 - 2017. B.E. at Beihang University. Information Engineering

## Selected Publications


### _Large Language Model_
* [Arxiv 2023]  Y. Zhou, J. Li, Y.Xiang, **H.Yan**, L. Gui, Y. He. [The Mystery and Fascination of LLMs: A Comprehensive Survey on the Interpretation and Analysis of Emergent Abilities.](https://arxiv.org/abs/2311.00237)]
![In-Context Learning can Learn Different Algorithm](/images/survey_macro.png)
  * In-Context Learning can Learn Different Algorithm

* [Under Review] **H. Yan**, Q. Zhu, X. Wang, L. Gui, Y. He. <ins>_Steer the LLMs in the self-refinement loop via unsupervised Reward_.</ins>


### _Self-Explainable Framework for Supervised Model_

* [Under Review] **H. Yan**, L. Gui, M. Wang, K. Zhang and Y. He. 
 [Explainable Recommender with Geometric Information Bottleneck](https://arxiv.org/abs/2305.05331)
![In-Context Learning can Learn Different Algorithm](/images/giant.png)
  * To avoid the expensive human annotation process and to generate explanations beyond individual reviews, we propose to incorporate a geometric prior learnt from user-item interactions into the latent factors from user-item reviews.

* [Computational Linguistics, Present at EMNLP23] **H. Yan**, L. Gui, Yulan He. [Hierarchical Interpretation of Neural Text Classification](https://direct.mit.edu/coli/article/doi/10.1162/coli_a_00459/112768/Hierarchical-Interpretation-of-Neural-Text).
![Giant](/images/hint.png)
  * 
  
* [ACL21, Oral] **H. Yan**, L. Gui, G. Pergola and Y. He. [A Knowledge-Aware Graph Model for Emotion Cause Extraction](https://aclanthology.org/2021.acl-long.261.pdf).
![kag](/images/)

_Efficient Robust Learning for Transformer-based models_
* [UAI2021, Spotlight] [[Addressing Token Uniformity in Transformers via Singular Value Transformation](https://proceedings.mlr.press/v180/yan22b.html)]
  * **H. Yan**, L. Gui, Y. He.

* [EACL23 findings] [Distinguishability Calibration to In-Context Learning](https://arxiv.org/abs/2302.06198)
  * **H. Yan**, H. Li, Y. Li, L. Qian, Y. He and L. Gui. 

## Professional Service

* Event Organizer:  Co-Chair of AACL-IJCNLP (Student Research Workshop) 2022 
* Reviewers for NLP Community: ACL23', EMNLP22',23', NAACL24', EACL23', AACL24', ACL Rolling Review
* Reviewers: Reviewer for ML community: UAI23', AISTATS24'
*  Journal Reviewer: Neurocomputing, Transactions on Information Systems (TOIS)

## Blog Posts
* _Reading List For Large Language Model_ (https://github.com/hanqi-qi/Large_language_modeling/blob/main/Reading_Material.md)

* _Induction Head_ contribute to In-context Learning [[ZhiHu](https://zhuanlan.zhihu.com/p/652269984)]

* _Causal101_ [[slides](https://github.com/hanqi-qi/NLPReadingGroup/blob/main/CausalInference/CausalInference_Intro_hanqi.pdf)]
* _Debised Recommendation with Causality_ [Slides](https://github.com/hanqi-qi/NLPReadingGroup/blob/main/CausalInference/CausalInference_RS_hanqi.pdf)
* _TakeAways from EMNLP23 Causality Tutorial_ [slides](https://drive.google.com/file/d/1u57NrYyKyEkMRGdYf5Mgdp0lBmK2UxZi/view)

* _Indentifiablity101 in Causality_ [ZhiHu](https://zhuanlan.zhihu.com/p/665841340)
